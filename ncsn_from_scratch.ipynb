{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430f99bc",
   "metadata": {},
   "source": [
    "> This notebook is adapted from the official implementation: https://github.com/ermongroup/ncsn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa0d44f",
   "metadata": {},
   "source": [
    "# A Noise Conditional Score Network (NCSN) applied to MNIST\n",
    "\n",
    "This notebook demonstrates how to implement a Noise Conditional Score Network (NCSN) from scratch, specifically applied to the MNIST dataset. It is part of the hands-on section of the Diffusion Models Minicourse at SBBD 2025.\n",
    "\n",
    "NCSNs are a class of generative models that learn to estimate score functions (gradients of the log data density) at multiple noise levels, allowing us to generate new data samples using annealed Langevin dynamics.\n",
    "\n",
    "## Import dependencies\n",
    "We start by importing all necessary libraries for data handling, model building, training, and visualization. This includes PyTorch for deep learning, torchvision for datasets and transforms, and matplotlib for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11d0d42cbdc94a03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T16:26:56.403021Z",
     "start_time": "2025-09-26T16:26:56.400179Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from models.ncsn import CondRefineNetDilated\n",
    "from torchvision.utils import make_grid, save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8ee8492a386825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T16:17:38.094256Z",
     "start_time": "2025-09-26T16:17:38.076720Z"
    }
   },
   "outputs": [],
   "source": [
    "load_model = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791058b0",
   "metadata": {},
   "source": [
    "Variable that controls if the model will be retrained or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2ae7530905e14a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T16:32:04.719510Z",
     "start_time": "2025-09-26T16:32:04.716299Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "device = 'cuda'\n",
    "\n",
    "# Model parameters\n",
    "sigma_begin = 1.0\n",
    "sigma_end = 0.01\n",
    "num_classes = 10  # Number of noise levels\n",
    "ngf = 64  # Number of generator features\n",
    "\n",
    "# Training parameters\n",
    "anneal_power = 2.0\n",
    "weight_decay = 0.0\n",
    "beta1 = 0.9\n",
    "amsgrad = False\n",
    "\n",
    "# Data parameters\n",
    "image_size = 28\n",
    "channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d238aecc",
   "metadata": {},
   "source": [
    "## Implementation of the Conditional RefineNet\n",
    "\n",
    "The Conditional RefineNet is a neural network architecture designed to estimate score functions at different noise levels. Unlike the U-Net used in DDPMs, the RefineNet uses dilated convolutions and multi-scale feature refinement to capture different levels of detail in the data.\n",
    "\n",
    "The network takes as input a noisy image and a noise level (class), and outputs the estimated score function (gradient of log-likelihood) for that specific noise level. This conditioning on noise levels is crucial for the annealed Langevin dynamics sampling procedure.\n",
    "\n",
    "Architecture:\n",
    "The model uses a series of dilated convolutional blocks that can capture both local and global dependencies in the data. The noise level conditioning is achieved through class embeddings that are injected into the network at multiple scales.\n",
    "\n",
    "The code of the Conditional RefineNet implementation is available on file [models/ncsn.py](./models/ncsn.py).\n",
    "\n",
    "## Noise schedule\n",
    "\n",
    "The noise schedule in NCSN defines the different noise levels Ïƒ_i that the model will learn to handle. Unlike DDPMs which use a forward diffusion process, NCSNs directly define a geometric sequence of noise levels from high to low values. This schedule is crucial for effective training and sampling.\n",
    "\n",
    "## Training and model parameters\n",
    "\n",
    "Here we define the key hyperparameters for training the NCSN, including noise levels, learning rate, batch size, and model parameters. The noise schedule is crucial as it determines the range of noise levels the model will learn to denoise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5ad8960d8c44ee7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T16:17:38.107997Z",
     "start_time": "2025-09-26T16:17:38.105381Z"
    }
   },
   "outputs": [],
   "source": [
    "tran_transform = test_transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94b85fd97c429e24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T16:17:38.148538Z",
     "start_time": "2025-09-26T16:17:38.113974Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = MNIST(\n",
    "    \"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "test_dataset = MNIST(\n",
    "    \"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Concatenate training and test data\n",
    "dataset = ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "# Create data loader\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec64daaf",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "We load the MNIST dataset, which consists of handwritten digit images. Both the training and test sets are combined to maximize the available data. Images are resized to 28x28 and normalized to [0, 1] range. A data loader is created to efficiently batch and shuffle the data during training. An example image is displayed to verify the data loading process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f306db5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show example image\n",
    "X_example = next(iter(dataloader))[0][0]\n",
    "plt.imshow(X_example.detach().cpu().numpy().squeeze(), cmap='Greys')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a8c2f061683daaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T16:17:44.245787Z",
     "start_time": "2025-09-26T16:17:44.041433Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CondRefineNetDilated(\n",
    "    logit_transform=False,\n",
    "    ngf=ngf,\n",
    "    num_classes=num_classes,\n",
    "    image_size=image_size,\n",
    "    channels=channels\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94f781",
   "metadata": {},
   "source": [
    "## Instantiate the model\n",
    "\n",
    "We instantiate the Conditional RefineNet model, which will be trained to estimate the score function for different noise levels. The model is moved to the selected device (CPU or GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6407e0dd7d60027b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T16:17:44.684620Z",
     "start_time": "2025-09-26T16:17:44.681154Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    betas=(beta1, 0.999),\n",
    "    amsgrad=amsgrad,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7a5c9f",
   "metadata": {},
   "source": [
    "## Optimizer and loss function\n",
    "\n",
    "We use the Adam optimizer to train the model. The loss function is the annealed denoising score matching (DSM) objective, which encourages the model to estimate the score function for each noise level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af6021812c8931a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise levels (sigmas): [1.         0.59948426 0.35938138 0.21544346 0.12915497 0.07742637\n",
      " 0.04641589 0.02782559 0.01668101 0.01      ]\n"
     ]
    }
   ],
   "source": [
    "sigmas = torch.tensor(\n",
    "    np.exp(np.linspace(np.log(sigma_begin), np.log(sigma_end), num_classes))\n",
    ").float().to(device)\n",
    "print('Noise levels (sigmas):', sigmas.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d000eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anneal_dsm_score_estimation(scorenet, samples, labels, sigmas, anneal_power=2.):\n",
    "    used_sigmas = sigmas[labels].view(samples.shape[0], *([1] * len(samples.shape[1:])))\n",
    "    perturbed_samples = samples + torch.randn_like(samples) * used_sigmas\n",
    "    target = - 1 / (used_sigmas ** 2) * (perturbed_samples - samples)\n",
    "    scores = scorenet(perturbed_samples, labels)\n",
    "    target = target.view(target.shape[0], -1)\n",
    "    scores = scores.view(scores.shape[0], -1)\n",
    "    loss = 1 / 2. * ((scores - target) ** 2).sum(dim=-1) * used_sigmas.squeeze() ** anneal_power\n",
    "\n",
    "    return loss.mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a295b0",
   "metadata": {},
   "source": [
    "## Annealed denoising score matching (DSM) loss\n",
    "\n",
    "The DSM loss is used to train the score network. For each batch, we sample a noise level, perturb the data, and train the model to predict the score (gradient of log-likelihood) for that noise level. The loss is averaged over the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "576dc38f97ad305",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T16:24:27.662481Z",
     "start_time": "2025-09-26T16:19:46.431370Z"
    }
   },
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    model.load_state_dict(torch.load('./weights/ncsn_100epochs.pickle', map_location=device))\n",
    "else:\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for i, (X, y) in enumerate(dataloader):\n",
    "            model.train()\n",
    "            X = X.to(device)\n",
    "            X = X / 256. * 255. + torch.rand_like(X) / 256.\n",
    "\n",
    "            labels = torch.randint(0, len(sigmas), (X.shape[0],), device=X.device)\n",
    "            loss = anneal_dsm_score_estimation(model, X, labels, sigmas, anneal_power)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7f533a",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "This section covers the training loop for the NCSN. The model learns to predict the score function for images perturbed by different noise levels. The optimizer updates the model weights to minimize the DSM loss. Periodic checkpoints can be saved for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dbb79cac79a4324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T16:35:38.324690Z",
     "start_time": "2025-09-26T16:35:38.320502Z"
    }
   },
   "outputs": [],
   "source": [
    "def anneal_Langevin_dynamics(x_mod, scorenet, sigmas, n_steps_each=100, step_lr=0.00002):\n",
    "    images = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for c, sigma in tqdm(enumerate(sigmas), total=len(sigmas), desc='annealed Langevin dynamics sampling'):\n",
    "            labels = torch.ones(x_mod.shape[0], device=x_mod.device) * c\n",
    "            labels = labels.long()\n",
    "            step_size = step_lr * (sigma / sigmas[-1]) ** 2\n",
    "            for s in range(n_steps_each):\n",
    "                noise = torch.randn_like(x_mod) * torch.sqrt(step_size * 2)\n",
    "                grad = scorenet(x_mod, labels)\n",
    "                x_mod = x_mod + step_size * grad + noise\n",
    "            images.append(torch.clamp(x_mod, 0.0, 1.0).to('cpu'))\n",
    "\n",
    "        return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fe0f64",
   "metadata": {},
   "source": [
    "## Sampling with annealed Langevin dynamics\n",
    "\n",
    "After training, we use annealed Langevin dynamics to generate new MNIST-like images from pure noise. The sampling function iteratively denoises a random image, reversing the noise process using the learned score network. Intermediate and final results are displayed to visualize the generative process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52e391e20e966392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T16:36:12.738196Z",
     "start_time": "2025-09-26T16:35:39.982898Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "annealed Langevin dynamics sampling:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "annealed Langevin dynamics sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:35<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "grid_size = 3\n",
    "samples = torch.rand(grid_size ** 2, 1, 28, 28, device=device)\n",
    "all_samples = anneal_Langevin_dynamics(samples, model, sigmas, n_steps_each=100, step_lr=0.00002)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcec4bb",
   "metadata": {},
   "source": [
    "## Generate and save images\n",
    "\n",
    "We use the trained NCSN to generate new samples. The images are saved in a grid format for visualization. This allows us to inspect the quality and diversity of the generated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebcc0c90d09031f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T16:36:12.829619Z",
     "start_time": "2025-09-26T16:36:12.806637Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "saving images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 545.38it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(tqdm(all_samples, total=len(all_samples), desc='saving images')):\n",
    "    sample = sample.view(grid_size ** 2, channels, image_size, image_size)\n",
    "    image_grid = make_grid(sample, nrow=grid_size)\n",
    "    save_image(image_grid, f'./samples/image_{i}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion-models-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
