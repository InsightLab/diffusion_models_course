{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d74064f",
   "metadata": {},
   "source": [
    "# High-Level Diffusion Models with Hugging Face Diffusers\n",
    "\n",
    "This notebook demonstrates how to use the Hugging Face `diffusers` library for diffusion models. It is part of the hands-on section of the Diffusion Models Minicourse at SBBD 2025.\n",
    "\n",
    "**Objectives:**\n",
    "- Use pre-built diffusion models with the `diffusers` library\n",
    "- Load datasets and generate samples\n",
    "- Customize and fine-tune diffusion models\n",
    "\n",
    "---\n",
    "\n",
    "> **Note:** This notebook requires the `diffusers` and `transformers` libraries. Install them with `pip install diffusers transformers` if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7335bdf0",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "Install the required libraries if you haven't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ee94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line if running for the first time\n",
    "# !pip install diffusers transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dcac73",
   "metadata": {},
   "source": [
    "## 2. Using Pretrained Diffusion Models\n",
    "\n",
    "Let's load a pretrained diffusion model and generate images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14245057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMPipeline\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load a pretrained DDPM pipeline (e.g., on MNIST)\n",
    "pipeline = DDPMPipeline.from_pretrained(\"google/ddpm-cifar10-32\")\n",
    "pipeline = pipeline.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate images\n",
    "images = pipeline(num_inference_steps=50).images\n",
    "\n",
    "# Plot generated images\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(images[i])\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bbebe8",
   "metadata": {},
   "source": [
    "## 3. Customizing and Fine-Tuning\n",
    "\n",
    "You can fine-tune diffusion models on your own dataset. See the [diffusers documentation](https://huggingface.co/docs/diffusers/training/overview) for detailed guides.\n",
    "\n",
    "Below is a minimal example of how you might set up a custom training pipeline (for demonstration only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d84ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Custom training setup (see diffusers docs for full details)\n",
    "# from diffusers import DDPMScheduler, UNet2DModel\n",
    "# model = UNet2DModel(...)\n",
    "# noise_scheduler = DDPMScheduler(...)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch in dataloader:\n",
    "#         ... # Training loop\n",
    "#         loss = ...\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "# print(\"Custom training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9715ed",
   "metadata": {},
   "source": [
    "## 4. Conclusion\n",
    "\n",
    "You have now seen how to use the Hugging Face `diffusers` library for high-level diffusion modeling. Explore the documentation for more advanced features, including training, conditional generation, and more!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
